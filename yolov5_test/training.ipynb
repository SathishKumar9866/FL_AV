{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import subprocess\n",
    "import socket\n",
    "from multiprocessing import Pool\n",
    "from models.yolo import Model\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "import flwr as fl\n",
    "import torchvision.transforms as transforms\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\SIU856522160\\\\Downloads'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change to a different directory\n",
    "os.chdir(r'C:\\Users\\SIU856522160\\Downloads')\n",
    "# Get the new default path\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (model): Sequential(\n",
      "    (0): Focus(\n",
      "      (conv): Conv(\n",
      "        (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (2): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (4): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (6): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (8): SPP(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "        (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
      "        (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (9): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): Conv(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (11): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (12): Concat()\n",
      "    (13): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): Conv(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (15): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (16): Concat()\n",
      "    (17): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (18): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (19): Concat()\n",
      "    (20): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (21): Conv(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (22): Concat()\n",
      "    (23): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (24): Detect(\n",
      "      (m): ModuleList(\n",
      "        (0): Conv2d(128, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(256, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): Conv2d(512, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load the YOLOv5 model\n",
    "model = Model('.\\\\yolov5\\models\\yolov5s.yaml')\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data from a client device\n",
    "def load_data_from_client(ip_address):\n",
    "    # Establish a connection with the client using its IP address\n",
    "    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    client_socket.connect((ip_address, 12345))  # Replace 12345 with the appropriate port number\n",
    "\n",
    "    # Send a request to the client to retrieve the data\n",
    "    client_socket.sendall(b\"GET_DATA\")\n",
    "\n",
    "    # Receive the data from the client\n",
    "    data = b\"\"\n",
    "    while True:\n",
    "        chunk = client_socket.recv(4096)\n",
    "        if not chunk:\n",
    "            break\n",
    "        data += chunk\n",
    "\n",
    "    # Close the connection with the client\n",
    "    client_socket.close()\n",
    "\n",
    "    # Convert the received data to the desired format (e.g., NumPy array, Torch tensor)\n",
    "    data = torch.from_numpy(data)  # Replace with the appropriate conversion method\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"person\", \"rider\", \"car\", \"truck\", \"bus\", \"train\", \"motor\", \"bike\", \"traffic light\", \"traffic sign\"]\n",
    "output_dir = r\".\\major\\output_yaml\"\n",
    "devices_folder = r\".\\vech\"\n",
    "output_yaml_path = r\".\\major\\output_yaml\"\n",
    "\n",
    "weights_path = r\".\\yolov5\\yolov5s.pt\"\n",
    "epochs = 300\n",
    "img_size = 640\n",
    "device = \"cuda\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset():\n",
    "    \n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.train_image_paths, self.train_annotations = self.load_data(\"train\")\n",
    "        self.val_image_paths, self.val_annotations = self.load_data(\"val\")\n",
    "\n",
    "    def load_data(self, subset):\n",
    "        image_paths = []\n",
    "        annotations = []\n",
    "        \n",
    "        subset_folder = os.path.join(self.data_path, subset)\n",
    "        image_files = [filename for filename in os.listdir(subset_folder) if filename.endswith('.jpg')]\n",
    "        \n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(subset_folder, image_file)\n",
    "            annotation = self.load_annotation(subset_folder, image_file) \n",
    "\n",
    "            image_paths.append(image_path)\n",
    "            annotations.append(annotation)\n",
    "\n",
    "        return image_paths, annotations\n",
    "\n",
    "    def load_annotation(self, subset_folder, image_file):\n",
    "        annotation_file = image_file.replace('.jpg', '.txt')\n",
    "        annotation_path = os.path.join(subset_folder, annotation_file)\n",
    "\n",
    "        with open(annotation_path, 'r') as file:\n",
    "            annotation_data = file.read()\n",
    "\n",
    "        return annotation_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_image_paths) + len(self.val_image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index < len(self.train_image_paths):\n",
    "            image_path = self.train_image_paths[index]\n",
    "            annotation = self.train_annotations[index]\n",
    "        else:\n",
    "            # Subtract the length of the train dataset to get the index for the val dataset\n",
    "            val_index = index - len(self.train_image_paths)\n",
    "            image_path = self.val_image_paths[val_index]\n",
    "            annotation = self.val_annotations[val_index]\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, annotation\n",
    "# data_path = r\"C:\\Users\\SIU856522160\\Downloads\\vech\\Device_3\\batch\"\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((416, 416)),  # Resize the image to YOLOv5 input size\n",
    "#     transforms.ToTensor(),  # Convert image to tensor\n",
    "# ])\n",
    "\n",
    "# data = CustomDataset(data_path, transform=transform)\n",
    "\n",
    "# train_dataset_length = len(data.train_image_paths)\n",
    "# val_dataset_length = len(data.val_image_paths)\n",
    "# print(f\"Number of samples in train dataset: {train_dataset_length}\")\n",
    "# print(f\"Number of samples in val dataset: {val_dataset_length}\")\n",
    "\n",
    "# # Access a single sample from the train dataset\n",
    "# train_sample_index = 0\n",
    "# train_image, train_annotation = data[train_sample_index]\n",
    "\n",
    "# # Access a single sample from the val dataset\n",
    "# val_sample_index = 0\n",
    "# val_image, val_annotation = data[val_sample_index]\n",
    "\n",
    "# num_samples = len(data)\n",
    "# print(f\"Number of samples in the dataset: {num_samples}\")\n",
    "\n",
    "# # Access a single sample\n",
    "# sample_index = 0\n",
    "# image, annotation = data[sample_index]\n",
    "# print(f\"Image shape: {image.shape}\")\n",
    "# print(f\"Annotation: {annotation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 87\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39m# Open the output file in write mode\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(output_file, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m---> 87\u001b[0m     process \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mPopen(command, stdout\u001b[39m=\u001b[39;49mfile, stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE)\n\u001b[0;32m     88\u001b[0m     _, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mcommunicate()\n\u001b[0;32m     90\u001b[0m     \u001b[39m# Print the error message if it exists\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SIU856522160\\Anaconda3\\envs\\venv\\lib\\subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    967\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[0;32m    968\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m    969\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m--> 971\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m    972\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m    973\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m    974\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m    975\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m    976\u001b[0m                         errread, errwrite,\n\u001b[0;32m    977\u001b[0m                         restore_signals,\n\u001b[0;32m    978\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m    979\u001b[0m                         start_new_session)\n\u001b[0;32m    980\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    982\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mc:\\Users\\SIU856522160\\Anaconda3\\envs\\venv\\lib\\subprocess.py:1380\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1378\u001b[0m     args \u001b[39m=\u001b[39m list2cmdline([args])\n\u001b[0;32m   1379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1380\u001b[0m     args \u001b[39m=\u001b[39m list2cmdline(args)\n\u001b[0;32m   1382\u001b[0m \u001b[39mif\u001b[39;00m executable \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1383\u001b[0m     executable \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfsdecode(executable)\n",
      "File \u001b[1;32mc:\\Users\\SIU856522160\\Anaconda3\\envs\\venv\\lib\\subprocess.py:563\u001b[0m, in \u001b[0;36mlist2cmdline\u001b[1;34m(seq)\u001b[0m\n\u001b[0;32m    561\u001b[0m result \u001b[39m=\u001b[39m []\n\u001b[0;32m    562\u001b[0m needquote \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 563\u001b[0m \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(os\u001b[39m.\u001b[39mfsdecode, seq):\n\u001b[0;32m    564\u001b[0m     bs_buf \u001b[39m=\u001b[39m []\n\u001b[0;32m    566\u001b[0m     \u001b[39m# Add a space to separate this argument from the others\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SIU856522160\\Anaconda3\\envs\\venv\\lib\\os.py:823\u001b[0m, in \u001b[0;36m_fscodec.<locals>.fsdecode\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfsdecode\u001b[39m(filename):\n\u001b[0;32m    818\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Decode filename (an os.PathLike, bytes, or str) from the filesystem\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[39m    encoding with 'surrogateescape' error handler, return str unchanged. On\u001b[39;00m\n\u001b[0;32m    820\u001b[0m \u001b[39m    Windows, use 'strict' error handler if the file system encoding is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m \u001b[39m    'mbcs' (which is the default encoding).\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 823\u001b[0m     filename \u001b[39m=\u001b[39m fspath(filename)  \u001b[39m# Does type-checking of `filename`.\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filename, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m    825\u001b[0m         \u001b[39mreturn\u001b[39;00m filename\u001b[39m.\u001b[39mdecode(encoding, errors)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not int"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "# CHECKPOINT = \"distilbert-base-uncased\"  # transformer model checkpoint\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "class_names = [\"person\", \"rider\", \"car\", \"truck\", \"bus\", \"train\", \"motor\", \"bike\", \"traffic light\", \"traffic sign\"]\n",
    "output_dir = r\"C:\\Users\\SIU856522160\\Downloads\\major\\output_yaml\"\n",
    "devices_folder = r\"C:\\Users\\SIU856522160\\Downloads\\yolov5\\data\\vech\"\n",
    "output_yaml_path = r\"C:\\Users\\SIU856522160\\Downloads\\major\\output_yaml\"\n",
    "\n",
    "weights_path = r\"C:\\Users\\SIU856522160\\Downloads\\yolov5\\yolov5s.pt\"\n",
    "epochs = 12\n",
    "img_size = 1024\n",
    "device = 0\n",
    "\n",
    "completed_batches = set()\n",
    "\n",
    "def train_model(devices_folder, weights_path, epochs, img_size, device):\n",
    "    global completed_batches\n",
    "\n",
    "    for device_folder in os.listdir(devices_folder):\n",
    "        device_dir = os.path.join(devices_folder, device_folder)\n",
    "        if not os.path.isdir(device_dir):\n",
    "            continue\n",
    "\n",
    "        train_dir = device_dir\n",
    "        batch_dirs = [batch for batch in os.listdir(train_dir) if batch.startswith('SubData_')]\n",
    "        \n",
    "        batch_dirs = [batch for batch in batch_dirs if batch.split('_')[1] not in completed_batches]\n",
    "\n",
    "        if not batch_dirs:\n",
    "            print(f\"All batches for {device_folder} have already completed training. Skipping...\")\n",
    "            completed_batches.add(device_folder)\n",
    "            continue\n",
    "\n",
    "        selected_batch = batch_dirs[0]\n",
    "        \n",
    "        batch_num = selected_batch.split('_')[1]\n",
    "        dataset_yaml_path = f\"dataset_{device_folder}_batch_{batch_num}.yaml\"\n",
    "        dataset_yaml_full_path = os.path.join(output_dir, dataset_yaml_path)\n",
    "        print(dataset_yaml_path, dataset_yaml_full_path)\n",
    "        \n",
    "        command = [\n",
    "            \"python\", \"C:\\\\Users\\\\SIU856522160\\\\Downloads\\\\yolov5\\\\train.py\",\n",
    "            \"--batch\", \"8\",\n",
    "            \"--data\", dataset_yaml_full_path,\n",
    "            \"--weights\", weights_path,\n",
    "            \"--epochs\", str(epochs),\n",
    "            \"--img-size\", str(img_size),\n",
    "            \"--device\", str(device)\n",
    "        ]\n",
    "\n",
    "        print(f\"Training started for {device_folder}, Batch {batch_num}...\")\n",
    "        subprocess.run(command,shell=True, capture_output=True, text=True)\n",
    "\n",
    "        # for line in completed_process.stdout.splitlines():\n",
    "        #     print(line.strip())\n",
    "\n",
    "        # if completed_process.returncode == 0:\n",
    "        #     print(f\"Training completed for {device_folder}, Batch {batch_num}\")\n",
    "        #     completed_batches.add(batch_num)\n",
    "        # else:\n",
    "        #     print(f\"Error occurred during training for {device_folder}, Batch {batch_num}\")\n",
    "        #     print(completed_process.stderr)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 40 + \"\\n\")\n",
    "\n",
    "    print(\"Completed batches:\", completed_batches)\n",
    "\n",
    "# train_model(devices_folder, weights_path, epochs, img_size, device)\n",
    "# command = [\n",
    "#     \"python\", r\"C:\\\\Users\\\\SIU856522160\\\\Downloads\\\\yolov5\\\\train.py\",\n",
    "#     \"--batch\", \"8\",\n",
    "#     \"--data\", r\"C:\\Users\\SIU856522160\\Downloads\\major\\output_yaml\\dataset_Device_1_batch_1.yaml\",\n",
    "#     \"--weights\", weights_path,\n",
    "#     \"--epochs\", str(epochs),\n",
    "#     \"--img-size\", str(img_size),\n",
    "#     \"--device\", device\n",
    "\n",
    "# ]\n",
    "\n",
    "\n",
    "output_file = 'output.txt'  # Path to the output file\n",
    "\n",
    "# Open the output file in write mode\n",
    "with open(output_file, 'w') as file:\n",
    "    process = subprocess.Popen(command, stdout=file, stderr=subprocess.PIPE)\n",
    "    _, stderr = process.communicate()\n",
    "\n",
    "    # Print the error message if it exists\n",
    "    if stderr:\n",
    "        print(\"Standard Error:\")\n",
    "        print(stderr.decode(\"utf-8\"))  # Convert bytes to string using the appropriate encoding\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    net = model\n",
    "\n",
    "\n",
    "    # Flower client\n",
    "    class IMDBClient(fl.client.NumPyClient):\n",
    "        def get_parameters(self,config):\n",
    "            return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "        def fit(self, parameters):\n",
    "            # self.set_parameters(parameters)\n",
    "            print(\"Training Started...\")\n",
    "            train_model(devices_folder, weights_path, epochs, img_size, device)\n",
    "            print(\"Training Finished.\")\n",
    "            return self.get_parameters(), {}\n",
    "\n",
    "    # Start client\n",
    "    fl.client.start_numpy_client(server_address=\"127.0.0.1:8080\", client=IMDBClient())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-06-27 02:37:28,500 | grpc.py:50 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flwr 2023-06-27 02:37:28,518 | connection.py:38 | ChannelConnectivity.IDLE\n",
      "DEBUG flwr 2023-06-27 02:37:28,520 | connection.py:38 | ChannelConnectivity.READY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-06-27 02:38:20,986 | connection.py:109 | gRPC channel closed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[39mreturn\u001b[39;00m loss, \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mvalid_ds), {\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m: accuracy}\n\u001b[0;32m     23\u001b[0m \u001b[39m# Start Flower client\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m fl\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mstart_numpy_client(\n\u001b[0;32m     25\u001b[0m     server_address\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlocalhost:8080\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     26\u001b[0m     client\u001b[39m=\u001b[39;49mFlowerClient(),\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\SIU856522160\\Anaconda3\\envs\\venv\\lib\\site-packages\\flwr\\client\\app.py:214\u001b[0m, in \u001b[0;36mstart_numpy_client\u001b[1;34m(server_address, client, grpc_max_message_length, root_certificates)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Start a Flower NumPyClient which connects to a gRPC server.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \n\u001b[0;32m    175\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39m>>> )\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[39m# Start\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m start_client(\n\u001b[0;32m    215\u001b[0m     server_address\u001b[39m=\u001b[39;49mserver_address,\n\u001b[0;32m    216\u001b[0m     client\u001b[39m=\u001b[39;49m_wrap_numpy_client(client\u001b[39m=\u001b[39;49mclient),\n\u001b[0;32m    217\u001b[0m     grpc_max_message_length\u001b[39m=\u001b[39;49mgrpc_max_message_length,\n\u001b[0;32m    218\u001b[0m     root_certificates\u001b[39m=\u001b[39;49mroot_certificates,\n\u001b[0;32m    219\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\SIU856522160\\Anaconda3\\envs\\venv\\lib\\site-packages\\flwr\\client\\app.py:145\u001b[0m, in \u001b[0;36mstart_client\u001b[1;34m(server_address, client, grpc_max_message_length, root_certificates)\u001b[0m\n\u001b[0;32m    142\u001b[0m receive, send \u001b[39m=\u001b[39m conn\n\u001b[0;32m    144\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     server_message \u001b[39m=\u001b[39m receive()\n\u001b[0;32m    146\u001b[0m     client_message, sleep_duration, keep_going \u001b[39m=\u001b[39m handle(\n\u001b[0;32m    147\u001b[0m         client, server_message\n\u001b[0;32m    148\u001b[0m     )\n\u001b[0;32m    149\u001b[0m     send(client_message)\n",
      "File \u001b[1;32mc:\\Users\\SIU856522160\\Anaconda3\\envs\\venv\\lib\\site-packages\\flwr\\client\\grpc_client\\connection.py:101\u001b[0m, in \u001b[0;36mgrpc_connection.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     97\u001b[0m stub \u001b[39m=\u001b[39m FlowerServiceStub(channel)\n\u001b[0;32m     99\u001b[0m server_message_iterator: Iterator[ServerMessage] \u001b[39m=\u001b[39m stub\u001b[39m.\u001b[39mJoin(\u001b[39miter\u001b[39m(queue\u001b[39m.\u001b[39mget, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m--> 101\u001b[0m receive: Callable[[], ServerMessage] \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m: \u001b[39mnext\u001b[39;49m(server_message_iterator)\n\u001b[0;32m    102\u001b[0m send: Callable[[ClientMessage], \u001b[39mNone\u001b[39;00m] \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m msg: queue\u001b[39m.\u001b[39mput(msg, block\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    104\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\SIU856522160\\Anaconda3\\envs\\venv\\lib\\site-packages\\grpc\\_channel.py:426\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 426\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next()\n",
      "File \u001b[1;32mc:\\Users\\SIU856522160\\Anaconda3\\envs\\venv\\lib\\site-packages\\grpc\\_channel.py:817\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_response_ready\u001b[39m():\n\u001b[0;32m    812\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mresponse \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m\n\u001b[0;32m    813\u001b[0m             (cygrpc\u001b[39m.\u001b[39mOperationType\u001b[39m.\u001b[39mreceive_message\n\u001b[0;32m    814\u001b[0m              \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mdue \u001b[39mand\u001b[39;00m\n\u001b[0;32m    815\u001b[0m              \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mcode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m--> 817\u001b[0m _common\u001b[39m.\u001b[39;49mwait(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_state\u001b[39m.\u001b[39;49mcondition\u001b[39m.\u001b[39;49mwait, _response_ready)\n\u001b[0;32m    818\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mresponse \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    819\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mresponse\n",
      "File \u001b[1;32mc:\\Users\\SIU856522160\\Anaconda3\\envs\\venv\\lib\\site-packages\\grpc\\_common.py:141\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(wait_fn, wait_complete_fn, timeout, spin_cb)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m wait_complete_fn():\n\u001b[1;32m--> 141\u001b[0m         _wait_once(wait_fn, MAXIMUM_WAIT_TIMEOUT, spin_cb)\n\u001b[0;32m    142\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m+\u001b[39m timeout\n",
      "File \u001b[1;32mc:\\Users\\SIU856522160\\Anaconda3\\envs\\venv\\lib\\site-packages\\grpc\\_common.py:106\u001b[0m, in \u001b[0;36m_wait_once\u001b[1;34m(wait_fn, timeout, spin_cb)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wait_once\u001b[39m(wait_fn, timeout, spin_cb):\n\u001b[1;32m--> 106\u001b[0m     wait_fn(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m spin_cb \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m         spin_cb()\n",
      "File \u001b[1;32mc:\\Users\\SIU856522160\\Anaconda3\\envs\\venv\\lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[0;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # Define Flower client\n",
    "# class FlowerClient(fl.client.NumPyClient):\n",
    "#     def get_parameters(self, config):\n",
    "#         return [val.detach().cpu().numpy() for _, val in model.named_parameters()]\n",
    "\n",
    "\n",
    "#     def set_parameters(self, parameters):\n",
    "#         for param, parameter in zip(model.parameters(), parameters):\n",
    "#             param.data = torch.from_numpy(parameter)\n",
    "\n",
    "#     def fit_round(self, parameters, client_info):\n",
    "#         self.global_model.aggregate_parameters(parameters)\n",
    "\n",
    "\n",
    "#     def evaluate(self, parameters, config):\n",
    "#         self.set_parameters(parameters)\n",
    "#         metrics = model.evaluate(data.valid_dataloader)\n",
    "#         loss = metrics[\"val_loss\"]\n",
    "#         accuracy = 1 - metrics[\"val_err\"]\n",
    "#         return loss, len(data.valid_ds), {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "# # Start Flower client\n",
    "# fl.client.start_numpy_client(\n",
    "#     server_address=\"localhost:8080\",\n",
    "#     client=FlowerClient(),\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming you have a list of client IP addresses\n",
    "# client_ip_addresses = [\"192.168.0.1\", \"192.168.0.2\", \"192.168.0.3\"]\n",
    "\n",
    "# # Function to load and preprocess client data\n",
    "# def load_and_preprocess_data(ip_address):\n",
    "#     try:\n",
    "#         data = load_data_from_client(ip_address)  # Function to load data from a client device\n",
    "#         preprocessed_data = preprocess_data(data)  # Function to preprocess the data\n",
    "#         return preprocessed_data\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error loading data from {ip_address}: {str(e)}\")\n",
    "#         return None\n",
    "\n",
    "# # Function to train local model and send model update\n",
    "# def train_local_model_and_send_update(args):\n",
    "#     data, ip_address = args\n",
    "#     try:\n",
    "#         local_model = create_model()  # Function to create a machine learning model\n",
    "#         local_model.train(data)  # Train the local model using the client data\n",
    "\n",
    "#         model_update = local_model.get_update()  # Get the model update (gradients or weights)\n",
    "\n",
    "#         # Send the model update to the central server using the client's IP address\n",
    "#         send_update_to_server(model_update, ip_address)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error training model or sending update from {ip_address}: {str(e)}\")\n",
    "\n",
    "# # Load and preprocess client data in parallel\n",
    "# with Pool() as pool:\n",
    "#     client_data = pool.map(load_and_preprocess_data, client_ip_addresses)\n",
    "\n",
    "# # Train local models and send model updates in parallel\n",
    "# with Pool() as pool:\n",
    "#     pool.map(train_local_model_and_send_update, zip(client_data, client_ip_addresses))\n",
    "\n",
    "# # Aggregate model updates on the central server and update the global model\n",
    "# aggregated_update = aggregate_model_updates()\n",
    "# global_model.update(aggregated_update)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Acquire client data\n",
    "# # Assuming you have your own code to load and preprocess client data\n",
    "# client_data = ...\n",
    "\n",
    "# # Define optimization algorithm\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# # Define loss function\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# # Define number of training epochs\n",
    "# num_epochs = 10\n",
    "\n",
    "# # Perform local training\n",
    "# for epoch in range(num_epochs):\n",
    "#     for images, labels in client_data:\n",
    "#         # Forward pass\n",
    "#         outputs = model(images)\n",
    "        \n",
    "#         # Compute loss\n",
    "#         loss = criterion(outputs, labels)\n",
    "        \n",
    "#         # Backward pass and optimization\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "# # Evaluation (optional)\n",
    "# validation_data = ...  # Assuming you have a validation dataset\n",
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     for val_images, val_labels in validation_data:\n",
    "#         val_outputs = model(val_images)\n",
    "#         # Compute evaluation metrics or perform validation tasks\n",
    "\n",
    "# # Send updated model parameters back to the server (communication step depends on your setup)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
