{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n",
      "True\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Fri_Dec_17_18:28:54_Pacific_Standard_Time_2021\n",
      "Cuda compilation tools, release 11.6, V11.6.55\n",
      "Build cuda_11.6.r11.6/compiler.30794723_0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# # Change to a different directory\n",
    "# os.chdir(r'C:\\Users\\SIU856522160\\Downloads')\n",
    "# # Get the new default path\n",
    "# os.getcwd()\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##install packages\n",
    "!pip install GPUtil pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import gc\n",
    "# import GPUtil\n",
    "# from IPython.display import Image, clear_output  # to display images\n",
    "# GPUtil.getAvailable()\n",
    "# torch.cuda.is_available()\n",
    "\n",
    "# gc.collect()\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # def report_gpu():\n",
    "# #    print(torch.cuda.list_gpu_processes())\n",
    "# #    gc.collect()\n",
    "# #    torch.cuda.empty_cache()\n",
    "# # report_gpu()\n",
    "\n",
    "\n",
    "# clear_output()\n",
    "# print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")\n",
    "\n",
    "\n",
    "# print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "# print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "# print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "# print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import gc\n",
    "# import GPUtil\n",
    "# from IPython.display import Image, clear_output  # to display images\n",
    "# GPUtil.getAvailable()\n",
    "# torch.cuda.is_available()\n",
    "\n",
    "# gc.collect()\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # def report_gpu():\n",
    "# #    print(torch.cuda.list_gpu_processes())\n",
    "# #    gc.collect()\n",
    "# #    torch.cuda.empty_cache()\n",
    "# # report_gpu()\n",
    "\n",
    "\n",
    "# clear_output()\n",
    "# print(\n",
    "#     f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")\n",
    "\n",
    "\n",
    "# print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "# print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "# print('__CUDA Device Name:', torch.cuda.get_device_name(0))\n",
    "# print('__CUDA Device Total Memory [GB]:', torch.cuda.get_device_properties(\n",
    "#     0).total_memory/1e9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='2, 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import subprocess\n",
    "\n",
    "# def train_model(devices_folder, weights_path, epochs, img_size, device):\n",
    "#     for device_folder in os.listdir(devices_folder):\n",
    "#         device_dir = os.path.join(devices_folder, device_folder)\n",
    "#         if not os.path.isdir(device_dir):\n",
    "#             continue\n",
    "\n",
    "#         train_dir = os.path.join(device_dir, 'train')\n",
    "#         batch_dirs = [batch for batch in os.listdir(train_dir) if batch.startswith('Batch_')]\n",
    "#         print(batch_dirs)\n",
    "#         for batch_dir in batch_dirs:\n",
    "#             batch_num = batch_dir.split('_')[1]\n",
    "#             dataset_yaml_path = f\"dataset_{device_folder}_batch{batch_num}.yaml\"\n",
    "#             print(dataset_yaml_path)\n",
    "#             # Construct the command to train the model\n",
    "#             command = [\n",
    "#                 \"python\", r\"C:\\Users\\SIU856522160\\Downloads\\yolov5\\train.py\",\n",
    "#                 \"--batch\", \"16\",\n",
    "#                 \"--data\", os.path.join(r\"C:\\Users\\SIU856522160\\Downloads\\major\\output_yaml\\\\\",dataset_yaml_path),\n",
    "#                 \"--weights\", weights_path,\n",
    "#                 \"--epochs\", str(epochs),\n",
    "#                 \"--img-size\", str(img_size),\n",
    "#                 \"--device\", str(device)\n",
    "#             ]\n",
    "\n",
    "#             # Execute the command\n",
    "#             process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "#             stdout, stderr = process.communicate()\n",
    "\n",
    "#             if process.returncode == 0:\n",
    "#                 print(f\"Training completed for {device_folder}, Batch {batch_num}\")\n",
    "#             else:\n",
    "#                 print(f\"Error occurred during training for {device_folder}, Batch {batch_num}\")\n",
    "#                 print(stderr.decode())\n",
    "\n",
    "#     print(\"Training completed for all devices and batches.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msathishkumarchary141\u001b[0m (\u001b[33msurya_786\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\SIU856522160\\Downloads\\yolov5\\wandb\\run-20230908_014513-2dc43444</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/surya_786/test/runs/2dc43444\" target=\"_blank\">warm-resonance-3</a></strong> to <a href=\"https://wandb.ai/surya_786/test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▆▆▇███</td></tr><tr><td>loss</td><td>█▆▇▆▅▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.74983</td></tr><tr><td>loss</td><td>0.2479</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">warm-resonance-3</strong>: <a href=\"https://wandb.ai/surya_786/test/runs/2dc43444\" target=\"_blank\">https://wandb.ai/surya_786/test/runs/2dc43444</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230908_014513-2dc43444\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"test\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 5,\n",
    "    }\n",
    ")\n",
    "\n",
    "# simulate training\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "    \n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "    \n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'wandb' has no attribute 'login'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m wandb\u001b[39m.\u001b[39;49mlogin()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'wandb' has no attribute 'login'"
     ]
    }
   ],
   "source": [
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import subprocess\n",
    "\n",
    "# class_names = [\"person\", \"rider\", \"car\", \"truck\", \"bus\", \"train\", \"motor\", \"bike\", \"traffic light\", \"traffic sign\"]\n",
    "# output_dir = r\"C:\\Users\\SIU856522160\\Downloads\\major\\output_yaml\"\n",
    "# devices_folder = r\"C:\\Users\\SIU856522160\\Downloads\\yolov5\\data\\vech\"\n",
    "# output_yaml_path = r\"C:\\Users\\SIU856522160\\Downloads\\major\\output_yaml\"\n",
    "\n",
    "# weights_path = r\"C:\\Users\\SIU856522160\\Downloads\\yolov5\\yolov5s.pt\"\n",
    "# epochs = 12\n",
    "# img_size = 1024\n",
    "# device = 0\n",
    "\n",
    "# completed_batches = set()\n",
    "\n",
    "# def train_model(devices_folder, weights_path, epochs, img_size, device):\n",
    "#     global completed_batches\n",
    "\n",
    "#     for device_folder in os.listdir(devices_folder):\n",
    "#         device_dir = os.path.join(devices_folder, device_folder)\n",
    "#         if not os.path.isdir(device_dir):\n",
    "#             continue\n",
    "\n",
    "#         train_dir = device_dir\n",
    "#         batch_dirs = [batch for batch in os.listdir(train_dir) if batch.startswith('SubData_')]\n",
    "        \n",
    "#         batch_dirs = [batch for batch in batch_dirs if batch.split('_')[1] not in completed_batches]\n",
    "\n",
    "#         if not batch_dirs:\n",
    "#             print(f\"All batches for {device_folder} have already completed training. Skipping...\")\n",
    "#             completed_batches.add(device_folder)\n",
    "#             continue\n",
    "\n",
    "#         selected_batch = batch_dirs[0]\n",
    "        \n",
    "#         batch_num = selected_batch.split('_')[1]\n",
    "#         dataset_yaml_path = f\"dataset_{device_folder}_batch_{batch_num}.yaml\"\n",
    "#         dataset_yaml_full_path = os.path.join(output_dir, dataset_yaml_path)\n",
    "#         print(dataset_yaml_path, dataset_yaml_full_path)\n",
    "        \n",
    "#         command = [\n",
    "#             \"python\", \"C:\\\\Users\\\\SIU856522160\\\\Downloads\\\\yolov5\\\\train.py\",\n",
    "#             \"--batch\", \"8\",\n",
    "#             \"--data\", dataset_yaml_full_path,\n",
    "#             \"--weights\", weights_path,\n",
    "#             \"--epochs\", str(epochs),\n",
    "#             \"--img-size\", str(img_size),\n",
    "#             \"--device\", str(device)\n",
    "#         ]\n",
    "\n",
    "#         print(f\"Training started for {device_folder}, Batch {batch_num}...\")\n",
    "#         subprocess.run(command,shell=True, capture_output=True, text=True)\n",
    "\n",
    "#         # for line in completed_process.stdout.splitlines():\n",
    "#         #     print(line.strip())\n",
    "\n",
    "#         # if completed_process.returncode == 0:\n",
    "#         #     print(f\"Training completed for {device_folder}, Batch {batch_num}\")\n",
    "#         #     completed_batches.add(batch_num)\n",
    "#         # else:\n",
    "#         #     print(f\"Error occurred during training for {device_folder}, Batch {batch_num}\")\n",
    "#         #     print(completed_process.stderr)\n",
    "\n",
    "#         print(\"\\n\" + \"=\" * 40 + \"\\n\")\n",
    "\n",
    "#     print(\"Completed batches:\", completed_batches)\n",
    "\n",
    "# # train_model(devices_folder, weights_path, epochs, img_size, device)\n",
    "# command = [\n",
    "#     \"python\", r\"C:\\\\Users\\\\SIU856522160\\\\Downloads\\\\yolov5\\\\train.py\",\n",
    "#     \"--batch\", \"8\",\n",
    "#     \"--data\", r\"C:\\Users\\SIU856522160\\Downloads\\major\\output_yaml\\dataset_Device_1_batch_1.yaml\",\n",
    "#     \"--weights\", weights_path,\n",
    "#     \"--epochs\", str(epochs),\n",
    "#     \"--img-size\", str(img_size),\n",
    "#     \"--device\", str(device)\n",
    "#     \"--save-txt\" ,\"output1.txt\"\n",
    "# ]\n",
    "\n",
    "\n",
    "# output_file = 'output.txt'  # Path to the output file\n",
    "\n",
    "# # Open the output file in write mode\n",
    "# with open(output_file, 'w') as file:\n",
    "#     process = subprocess.Popen(command, stdout=file, stderr=subprocess.PIPE)\n",
    "#     _, stderr = process.communicate()\n",
    "\n",
    "#     # Print the error message if it exists\n",
    "#     if stderr:\n",
    "#         print(\"Standard Error:\")\n",
    "#         print(stderr.decode(\"utf-8\"))  # Convert bytes to string using the appropriate encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=C:\\Users\\SIU856522160\\Downloads\\major\\output_yaml\\dataset_Device_1_batch_1.yaml, hyp=data\\hyps\\hyp.scratch.yaml, epochs=12, batch_size=16, imgsz=1024, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs\\train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: sathishkumarchary141 (surya_786). Use `wandb login --relogin` to force relogin\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SIU856522160\\Downloads\\yolov5\\train.py\", line 620, in <module>\n",
      "    main(opt)\n",
      "  File \"c:\\Users\\SIU856522160\\Downloads\\yolov5\\train.py\", line 497, in main\n",
      "    check_file(opt.data), check_yaml(opt.cfg), check_yaml(opt.hyp), str(opt.weights), str(opt.project)  # checks\n",
      "  File \"c:\\Users\\SIU856522160\\Downloads\\yolov5\\utils\\general.py\", line 325, in check_file\n",
      "    assert len(files), f'File not found: {file}'  # assert file was found\n",
      "AssertionError: File not found: C:\\Users\\SIU856522160\\Downloads\\major\\output_yaml\\dataset_Device_1_batch_1.yaml\n"
     ]
    }
   ],
   "source": [
    "# !python \"train.py\" --batch 16 --data \"C:\\Users\\SIU856522160\\Downloads\\major\\output_yaml\\dataset_Device_1_batch_1.yaml\" --weights yolov5s.pt  --epochs 12 --img-size 1024 --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=dataset.yaml, hyp=data\\hyps\\hyp.scratch.yaml, epochs=5, batch_size=8, imgsz=1024, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs\\train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "\n",
      "WARNING: Dataset not found, nonexistent paths: ['C:\\\\Users\\\\SIU856522160\\\\Downloads\\\\yolov5\\\\data\\\\100k\\\\valid.txt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: sathishkumarchary141 (surya_786). Use `wandb login --relogin` to force relogin\n",
      "YOLOv5  2023-2-20 torch 2.0.0+cu117 CUDA:0 (NVIDIA GeForce RTX 2060 SUPER, 8191.6875MB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.003, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n",
      "wandb: wandb version 0.15.10 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "wandb: Tracking run with wandb version 0.13.2\n",
      "wandb: Run data is saved locally in c:\\Users\\SIU856522160\\Downloads\\yolov5\\wandb\\run-20230908_014648-zlptuf7b\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run cerulean-water-11\n",
      "wandb:  View project at https://wandb.ai/surya_786/train\n",
      "wandb:  View run at https://wandb.ai/surya_786/train/runs/zlptuf7b\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SIU856522160\\Downloads\\yolov5\\train.py\", line 620, in <module>\n",
      "    main(opt)\n",
      "  File \"c:\\Users\\SIU856522160\\Downloads\\yolov5\\train.py\", line 517, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"c:\\Users\\SIU856522160\\Downloads\\yolov5\\train.py\", line 88, in train\n",
      "    loggers = Loggers(save_dir, weights, opt, hyp, LOGGER)  # loggers instance\n",
      "  File \"c:\\Users\\SIU856522160\\Downloads\\yolov5\\utils\\loggers\\__init__.py\", line 62, in __init__\n",
      "    self.wandb = WandbLogger(self.opt, run_id)\n",
      "  File \"c:\\Users\\SIU856522160\\Downloads\\yolov5\\utils\\loggers\\wandb\\wandb_utils.py\", line 183, in __init__\n",
      "    self.data_dict = check_wandb_dataset(opt.data)\n",
      "  File \"c:\\Users\\SIU856522160\\Downloads\\yolov5\\utils\\loggers\\wandb\\wandb_utils.py\", line 60, in check_wandb_dataset\n",
      "    return check_dataset(data_file)\n",
      "  File \"c:\\Users\\SIU856522160\\Downloads\\yolov5\\utils\\general.py\", line 377, in check_dataset\n",
      "    raise Exception('Dataset not found.')\n",
      "Exception: Dataset not found.\n"
     ]
    }
   ],
   "source": [
    "!python train.py --batch 8 --data dataset.yaml --weights yolov5s.pt  --epochs 5 --img-size 1024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python train.py --batch 16 --data dataset.yaml --weights yolov5s.pt  --epochs 10 --img-size 1024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python train.py --batch 16 --data dataset.yaml --weights yolov5s.pt  --epochs 120 --img-size 1024 --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python train.py --batch 16 --data dataset.yaml --weights yolov5s.pt  --epochs 120 --img-size 1024 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!wandb login 47afa783acc34077ddd564575ef37be72db9ffe9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python train.py --batch 16 --data dataset.yaml --weights yolov5s.pt  --epochs 2 --img-size 512 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbb7df8212c501dd8c2adbb725d9a6c9f6f2648703e0c80bc5b41f289866512f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
