{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to YOLO format: 100%|██████████| 69863/69863 [06:46<00:00, 171.81it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(filename='yolo_conversion_json_to_yolov5_100k.log', level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    \"person\": 0,\n",
    "    \"pedestrian\": 0,  # Merge pedestrian into person\n",
    "    \"rider\": 1,\n",
    "    \"car\": 2,\n",
    "    \"truck\": 3,\n",
    "    \"bus\": 4,\n",
    "    \"train\": 5,\n",
    "    \"motor\": 6,       # Motorcycle\n",
    "    \"motorcycle\": 6,  # Merge motorcycle into motor\n",
    "    \"bike\": 7,        # Bicycle\n",
    "    \"bicycle\": 7,     # Merge bicycle into bike\n",
    "    \"traffic light\": 8,\n",
    "    \"traffic sign\": 9,\n",
    "    \"trailer\": 10,\n",
    "    \"other person\": 11,\n",
    "    \"other vehicle\": 12\n",
    "}\n",
    "\n",
    "# Paths (Update these as needed)\n",
    "bdd_annotations_path_train = r\"C:\\Users\\sathish\\Downloads\\FL_ModelForAV\\data\\bdd100k\\label_json\\bdd100k_labels_images_train.json\"\n",
    "image_folder_path = r\"C:\\Users\\sathish\\Downloads\\FL_ModelForAV\\data\\bdd100k\\images\\train\"\n",
    "output_label_folder = r\"C:\\Users\\sathish\\Downloads\\FL_ModelForAV\\data\\bdd100k\\labels\\train\"\n",
    "\n",
    "# Create output folder\n",
    "os.makedirs(output_label_folder, exist_ok=True)\n",
    "\n",
    "# Load JSON annotations\n",
    "try:\n",
    "    with open(bdd_annotations_path_train, 'r') as file:\n",
    "        annotations = json.load(file)\n",
    "except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "    logging.error(f\"Error loading JSON file: {e}\")\n",
    "    raise SystemExit(f\"Error loading JSON file: {e}\")\n",
    "\n",
    "# Track statistics\n",
    "skipped_labels = 0\n",
    "unrecognized_categories = set()\n",
    "processed_images = 0\n",
    "successful_conversions = 0\n",
    "error_images = 0\n",
    "missing_images = 0\n",
    "\n",
    "logging.info(\"Starting YOLO conversion process...\")\n",
    "\n",
    "for annotation in tqdm(annotations, desc=\"Converting to YOLO format\"):\n",
    "    image_name = annotation['name']\n",
    "    labels = annotation.get('labels', [])\n",
    "    image_path = os.path.join(image_folder_path, image_name)\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        missing_images += 1\n",
    "        logging.warning(f\"Warning: Image {image_name} not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            image_width, image_height = img.size\n",
    "    except UnidentifiedImageError as e:\n",
    "        error_images += 1\n",
    "        logging.error(f\"Error opening image {image_name}: {e}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    processed_images += 1\n",
    "    label_file_path = os.path.join(output_label_folder, os.path.splitext(image_name)[0] + '.txt')\n",
    "\n",
    "    label_lines = []\n",
    "    for label in labels:\n",
    "        category = label.get('category', '').strip().lower()\n",
    "\n",
    "        # Skip unrecognized categories but log them\n",
    "        if category not in category_mapping:\n",
    "            unrecognized_categories.add(category)\n",
    "            logging.warning(f\"Skipping unrecognized category '{category}' in image {image_name}.\")\n",
    "            continue\n",
    "\n",
    "        class_id = category_mapping[category]\n",
    "\n",
    "        # Check for 'box2d' key\n",
    "        if 'box2d' not in label:\n",
    "            skipped_labels += 1\n",
    "            logging.warning(f\"Skipping label: 'box2d' missing for image {image_name}.\")\n",
    "            continue\n",
    "\n",
    "        x1, y1 = label['box2d']['x1'], label['box2d']['y1']\n",
    "        x2, y2 = label['box2d']['x2'], label['box2d']['y2']\n",
    "\n",
    "        x_center = ((x1 + x2) / 2) / image_width\n",
    "        y_center = ((y1 + y2) / 2) / image_height\n",
    "        width = (x2 - x1) / image_width\n",
    "        height = (y2 - y1) / image_height\n",
    "\n",
    "        label_lines.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "\n",
    "    # Write to label file only if there are valid labels\n",
    "    if label_lines:\n",
    "        try:\n",
    "            with open(label_file_path, 'w') as label_file:\n",
    "                label_file.write(\"\\n\".join(label_lines) + \"\\n\")\n",
    "            successful_conversions += len(label_lines)\n",
    "        except IOError as e:\n",
    "            error_images += 1\n",
    "            logging.error(f\"Error writing label file {label_file_path}: {e}\")\n",
    "    else:\n",
    "        logging.info(f\"Skipping file creation for {image_name} (no valid labels).\")\n",
    "\n",
    "    logging.info(f\"Processed image: {image_name}\")\n",
    "\n",
    "# Summary logging\n",
    "completion_msg = f\"Conversion complete! YOLOv5 labels saved in {output_label_folder}\"\n",
    "logging.info(completion_msg)\n",
    "\n",
    "stats_msg = (\n",
    "    f\"Total processed images: {processed_images}\\n\"\n",
    "    f\"Total successful label entries: {successful_conversions}\\n\"\n",
    "    f\"Total skipped labels due to missing 'box2d': {skipped_labels}\\n\"\n",
    "    f\"Total unrecognized categories: {len(unrecognized_categories)}\\n\"\n",
    "    f\"Total missing images: {missing_images}\\n\"\n",
    "    f\"Total error images (unreadable): {error_images}\"\n",
    ")\n",
    "logging.info(stats_msg)\n",
    "\n",
    "# Log unrecognized categories in a separate file\n",
    "if unrecognized_categories:\n",
    "    unrecognized_msg = f\"Unrecognized categories found: {', '.join(unrecognized_categories)}\"\n",
    "    logging.warning(unrecognized_msg)\n",
    "    with open(os.path.join(output_label_folder, \"unrecognized_categories.txt\"), \"w\") as f:\n",
    "        f.write(\"\\n\".join(sorted(unrecognized_categories)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to YOLO format: 100%|██████████| 10000/10000 [00:19<00:00, 514.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(filename='yolo_conversion_json_to_yolov5_val.log', level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    \"person\": 0,\n",
    "    \"pedestrian\": 0,  # Merge pedestrian into person\n",
    "    \"rider\": 1,\n",
    "    \"car\": 2,\n",
    "    \"truck\": 3,\n",
    "    \"bus\": 4,\n",
    "    \"train\": 5,\n",
    "    \"motor\": 6,       # Motorcycle\n",
    "    \"motorcycle\": 6,  # Merge motorcycle into motor\n",
    "    \"bike\": 7,        # Bicycle\n",
    "    \"bicycle\": 7,     # Merge bicycle into bike\n",
    "    \"traffic light\": 8,\n",
    "    \"traffic sign\": 9,\n",
    "    \"trailer\": 10,\n",
    "    \"other person\": 11,\n",
    "    \"other vehicle\": 12\n",
    "}\n",
    "\n",
    "# Paths (Update these as needed)\n",
    "bdd_annotations_path_val = r\"C:\\Users\\sathish\\Downloads\\FL_ModelForAV\\data\\bdd100k\\label_json\\bdd100k_labels_images_val.json\"\n",
    "image_folder_path = r\"C:\\Users\\sathish\\Downloads\\FL_ModelForAV\\data\\bdd100k\\images\\val\"\n",
    "output_label_folder = r\"C:\\Users\\sathish\\Downloads\\FL_ModelForAV\\data\\bdd100k\\labels\\val\"\n",
    "\n",
    "# Create output folder\n",
    "os.makedirs(output_label_folder, exist_ok=True)\n",
    "\n",
    "# Load JSON annotations\n",
    "try:\n",
    "    with open(bdd_annotations_path_val, 'r') as file:\n",
    "        annotations = json.load(file)\n",
    "except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "    logging.error(f\"Error loading JSON file: {e}\")\n",
    "    raise SystemExit(f\"Error loading JSON file: {e}\")\n",
    "\n",
    "# Track statistics\n",
    "skipped_labels = 0\n",
    "unrecognized_categories = set()\n",
    "processed_images = 0\n",
    "successful_conversions = 0\n",
    "error_images = 0\n",
    "missing_images = 0\n",
    "\n",
    "logging.info(\"Starting YOLO conversion process for validation dataset...\")\n",
    "\n",
    "for annotation in tqdm(annotations, desc=\"Converting to YOLO format\"):\n",
    "    image_name = annotation['name']\n",
    "    labels = annotation.get('labels', [])\n",
    "    image_path = os.path.join(image_folder_path, image_name)\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        missing_images += 1\n",
    "        logging.warning(f\"Warning: Image {image_name} not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            image_width, image_height = img.size\n",
    "    except UnidentifiedImageError as e:\n",
    "        error_images += 1\n",
    "        logging.error(f\"Error opening image {image_name}: {e}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    processed_images += 1\n",
    "    label_file_path = os.path.join(output_label_folder, os.path.splitext(image_name)[0] + '.txt')\n",
    "\n",
    "    label_lines = []\n",
    "    for label in labels:\n",
    "        category = label.get('category', '').strip().lower()\n",
    "\n",
    "        # Skip unrecognized categories but log them\n",
    "        if category not in category_mapping:\n",
    "            unrecognized_categories.add(category)\n",
    "            logging.warning(f\"Skipping unrecognized category '{category}' in image {image_name}.\")\n",
    "            continue\n",
    "\n",
    "        class_id = category_mapping[category]\n",
    "\n",
    "        # Check for 'box2d' key\n",
    "        if 'box2d' not in label:\n",
    "            skipped_labels += 1\n",
    "            logging.warning(f\"Skipping label: 'box2d' missing for image {image_name}.\")\n",
    "            continue\n",
    "\n",
    "        x1, y1 = label['box2d']['x1'], label['box2d']['y1']\n",
    "        x2, y2 = label['box2d']['x2'], label['box2d']['y2']\n",
    "\n",
    "        x_center = ((x1 + x2) / 2) / image_width\n",
    "        y_center = ((y1 + y2) / 2) / image_height\n",
    "        width = (x2 - x1) / image_width\n",
    "        height = (y2 - y1) / image_height\n",
    "\n",
    "        label_lines.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "\n",
    "    # Write to label file only if there are valid labels\n",
    "    if label_lines:\n",
    "        try:\n",
    "            with open(label_file_path, 'w') as label_file:\n",
    "                label_file.write(\"\\n\".join(label_lines) + \"\\n\")\n",
    "            successful_conversions += len(label_lines)\n",
    "        except IOError as e:\n",
    "            error_images += 1\n",
    "            logging.error(f\"Error writing label file {label_file_path}: {e}\")\n",
    "    else:\n",
    "        logging.info(f\"Skipping file creation for {image_name} (no valid labels).\")\n",
    "\n",
    "    logging.info(f\"Processed image: {image_name}\")\n",
    "\n",
    "# Summary logging\n",
    "completion_msg = f\"Validation dataset conversion complete! YOLOv5 labels saved in {output_label_folder}\"\n",
    "logging.info(completion_msg)\n",
    "\n",
    "stats_msg = (\n",
    "    f\"Total processed images: {processed_images}\\n\"\n",
    "    f\"Total successful label entries: {successful_conversions}\\n\"\n",
    "    f\"Total skipped labels due to missing 'box2d': {skipped_labels}\\n\"\n",
    "    f\"Total unrecognized categories: {len(unrecognized_categories)}\\n\"\n",
    "    f\"Total missing images: {missing_images}\\n\"\n",
    "    f\"Total error images (unreadable): {error_images}\"\n",
    ")\n",
    "logging.info(stats_msg)\n",
    "\n",
    "# Log unrecognized categories in a separate file\n",
    "if unrecognized_categories:\n",
    "    unrecognized_msg = f\"Unrecognized categories found: {', '.join(unrecognized_categories)}\"\n",
    "    logging.warning(unrecognized_msg)\n",
    "    with open(os.path.join(output_label_folder, \"unrecognized_categories.txt\"), \"w\") as f:\n",
    "        f.write(\"\\n\".join(sorted(unrecognized_categories)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging initialized. Check logs/process.log for details.\n",
      "Batch processing completed. Check logs/process.log for details.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "import logging\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# ======================= SETUP LOGGING ===========================\n",
    "def setup_logging():\n",
    "    \"\"\"Initializes logging for tracking dataset processing.\"\"\"\n",
    "    log_dir = \"logs\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_file = os.path.join(log_dir, \"process.log\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        filename=log_file,\n",
    "        filemode=\"w\"\n",
    "    )\n",
    "    print(\"Logging initialized. Check logs/process.log for details.\")\n",
    "    logging.info(\"Logging setup complete.\")\n",
    "\n",
    "setup_logging()\n",
    "\n",
    "# ======================= CATEGORY MAPPING ========================\n",
    "CATEGORY_MAPPING = {\n",
    "    \"person\": 0, \"rider\": 1, \"car\": 2, \"truck\": 3, \"bus\": 4,\n",
    "    \"train\": 5, \"motorcycle\": 6, \"bicycle\": 7, \"traffic light\": 8, \n",
    "    \"traffic sign\": 9, \"trailer\": 10, \"other person\": 11, \"other vehicle\": 12\n",
    "}\n",
    "\n",
    "CATEGORY_NAMES = [name for name, index in sorted(CATEGORY_MAPPING.items(), key=lambda item: item[1])]\n",
    "\n",
    "# ======================= INITIALIZE DATASET =======================\n",
    "def initialize_dataset_directory(dataset_path):\n",
    "    \"\"\"Ensures the dataset directory has the necessary structure and files.\"\"\"\n",
    "    logging.info(f\"Initializing dataset directory: {dataset_path}\")\n",
    "    \n",
    "    os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "    # Define necessary subdirectories\n",
    "    subdirs = [\"images/train\", \"images/val\", \"images/test\", \"labels/train\", \"labels/val\", \"labels/test\"]\n",
    "    for subdir in subdirs:\n",
    "        os.makedirs(os.path.join(dataset_path, subdir), exist_ok=True)\n",
    "\n",
    "    # Create/update data.yaml\n",
    "    data_yaml_path = os.path.join(dataset_path, \"data.yaml\")\n",
    "    data_yaml_content = {\n",
    "        \"path\": os.path.abspath(dataset_path),\n",
    "        \"train\": \"images/train\",\n",
    "        \"val\": \"images/val\",\n",
    "        \"test\": \"images/test\",\n",
    "        \"nc\": len(CATEGORY_NAMES),\n",
    "        \"names\": CATEGORY_NAMES\n",
    "    }\n",
    "    with open(data_yaml_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        yaml.dump(data_yaml_content, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "    # Create empty train.txt, val.txt, test.txt if they don’t exist\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        split_file = os.path.join(dataset_path, f\"{split}.txt\")\n",
    "        if not os.path.exists(split_file):\n",
    "            with open(split_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(\"\")  # Create empty file\n",
    "            logging.info(f\"Created empty {split}.txt in {dataset_path}\")\n",
    "\n",
    "    logging.info(f\"Dataset directory structure initialized in {dataset_path}.\")\n",
    "\n",
    "# ======================= CREATE MINI DATASET =======================\n",
    "def copy_files(source_file, dest_file):\n",
    "    \"\"\"Copies a file with error handling.\"\"\"\n",
    "    try:\n",
    "        shutil.copy2(source_file, dest_file)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error copying {source_file} to {dest_file}: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_mini_dataset(source_root, dest_root, num_images=10, num_batches=3, max_threads=5):\n",
    "    \"\"\"Creates a mini dataset by randomly selecting images and copying labels using multithreading.\"\"\"\n",
    "    if not os.path.exists(source_root):\n",
    "        logging.error(f\"Source directory '{source_root}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(dest_root, exist_ok=True)\n",
    "\n",
    "    for batch_num in range(1, num_batches + 1):\n",
    "        source_batch = os.path.join(source_root, f\"batch_{batch_num}\")\n",
    "        dest_batch = os.path.join(dest_root, f\"batch_{batch_num}\")\n",
    "\n",
    "        if not os.path.exists(source_batch):\n",
    "            logging.warning(f\"Skipping batch {batch_num}, missing: {source_batch}\")\n",
    "            continue\n",
    "\n",
    "        os.makedirs(dest_batch, exist_ok=True)\n",
    "\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            source_images_dir = os.path.join(source_batch, split, \"images\")\n",
    "            source_labels_dir = os.path.join(source_batch, split, \"labels\")\n",
    "            dest_images_dir = os.path.join(dest_batch, split, \"images\")\n",
    "            dest_labels_dir = os.path.join(dest_batch, split, \"labels\")\n",
    "\n",
    "            if not os.path.exists(source_images_dir):\n",
    "                logging.warning(f\"Skipping {split} in batch {batch_num}, missing: {source_images_dir}\")\n",
    "                continue\n",
    "\n",
    "            os.makedirs(dest_images_dir, exist_ok=True)\n",
    "            os.makedirs(dest_labels_dir, exist_ok=True)\n",
    "\n",
    "            image_files = [f for f in os.listdir(source_images_dir) if f.endswith(('.jpg', '.png'))]\n",
    "            if not image_files:\n",
    "                logging.warning(f\"No images found in {source_images_dir}, skipping...\")\n",
    "                continue\n",
    "\n",
    "            selected_images = random.sample(image_files, min(num_images, len(image_files)))\n",
    "\n",
    "            # Use multithreading to speed up file copying\n",
    "            with ThreadPoolExecutor(max_threads) as executor:\n",
    "                for image in selected_images:\n",
    "                    src_img = os.path.join(source_images_dir, image)\n",
    "                    dest_img = os.path.join(dest_images_dir, image)\n",
    "                    executor.submit(copy_files, src_img, dest_img)\n",
    "\n",
    "                    label_name = os.path.splitext(image)[0] + \".txt\"\n",
    "                    src_label = os.path.join(source_labels_dir, label_name)\n",
    "                    dest_label = os.path.join(dest_labels_dir, label_name)\n",
    "\n",
    "                    if os.path.exists(src_label):\n",
    "                        executor.submit(copy_files, src_label, dest_label)\n",
    "\n",
    "        # Copy `data.yaml` if it exists\n",
    "        source_yaml = os.path.join(source_batch, \"data.yaml\")\n",
    "        dest_yaml = os.path.join(dest_batch, \"data.yaml\")\n",
    "        if os.path.exists(source_yaml):\n",
    "            copy_files(source_yaml, dest_yaml)\n",
    "\n",
    "    logging.info(f\"Mini dataset created successfully at {dest_root}\")\n",
    "\n",
    "# ======================= PROCESS BATCHES =======================\n",
    "def process_batches(batch_root):\n",
    "    \"\"\"Main function to process dataset batches.\"\"\"\n",
    "    logging.info(f\"Starting batch processing in {batch_root}...\")\n",
    "\n",
    "    if not os.path.exists(batch_root):\n",
    "        logging.error(f\"Batch root directory {batch_root} does not exist.\")\n",
    "        return\n",
    "    \n",
    "    for batch in os.listdir(batch_root):\n",
    "        batch_path = os.path.join(batch_root, batch)\n",
    "        if os.path.isdir(batch_path):\n",
    "            logging.info(f\"Processing batch: {batch_path}\")\n",
    "            initialize_dataset_directory(batch_path)\n",
    "\n",
    "    logging.info(\"Batch processing completed successfully.\")\n",
    "    print(\"Batch processing completed. Check logs/process.log for details.\")\n",
    "\n",
    "# ======================= MAIN EXECUTION =======================\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path = r\"C:\\Users\\sathish\\Downloads\\FL_ModelForAV\\data\\bdd100k\"\n",
    "    mini_dataset_path = r\"C:\\Users\\sathish\\Downloads\\FL_ModelForAV\\my-project\\data\\bdd100_mini\"\n",
    "\n",
    "    # Initialize dataset structure\n",
    "    initialize_dataset_directory(dataset_path)\n",
    "\n",
    "    # Process existing batches\n",
    "    process_batches(dataset_path)\n",
    "\n",
    "    # Create mini dataset from original\n",
    "    create_mini_dataset(dataset_path, mini_dataset_path, num_images=10, num_batches=10, max_threads=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
